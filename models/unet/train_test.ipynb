{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import UNetDatasetSingle, UNetDatasetMult\n",
    "from unet import UNet1d, UNet2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "data_path = \"/data1/zhouziyang/datasets/pdebench/2D/Burgers/2D_Burgers_Nu0.001.hdf5\"\n",
    "f = h5py.File(data_path, 'r')\n",
    "seed_list = sorted(f.keys())\n",
    "print(seed_list[::1])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "flnm = \"2D_Burgers_Nu0.001.hdf5\"\n",
    "base_path = \"/data1/zhouziyang/datasets/pdebench/2D/Burgers/\"\n",
    "reduced_resolution = 1\n",
    "reduced_resolution_t = 1\n",
    "reduced_batch = 1\n",
    "initial_step = 10\n",
    "t_train = 101 # The number of time step in a sample \n",
    "unroll_step = 20 # unrolled time step for the pushforward trick\n",
    "batch_size = 8\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset and dataloader\n",
    "train_data = UNetDatasetMult(flnm,\n",
    "    saved_folder=base_path,\n",
    "    reduced_resolution=reduced_resolution,\n",
    "    reduced_resolution_t=reduced_resolution_t,\n",
    "    reduced_batch=reduced_batch,\n",
    "    initial_step=initial_step)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, Loss and Optimizer\n",
    "device = \"cuda:2\"\n",
    "model = UNet2d(2*initial_step, 2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample, y_sample = next(iter(train_loader))\n",
    "# training config (pushforward)\n",
    "t_train = min(t_train, y_sample.shape[-2]) # 41\n",
    "unroll_step = t_train - 1 if t_train - unroll_step < 1 else unroll_step # 20: 总要留出一个时间步的解作为target\n",
    "\n",
    "# train\n",
    "train_l2_step = 0\n",
    "train_l2_full = 0\n",
    "for x, y in train_loader:\n",
    "    # one iteration\n",
    "    loss = 0\n",
    "    x = x.to(device) # input tensor (bs, x, t, v): (16, 256, 10, 1)\n",
    "    y = y.to(device) # target tensor (bs, x, t, v): (16, 256, 41, 1)\n",
    "\n",
    "    pred = y[..., :initial_step, :] # (16, 256, 10, 1)\n",
    "    inp_shape = list(x.shape) # [16, 256, 10, 1]\n",
    "    inp_shape = inp_shape[:-2] # [16, 256]\n",
    "    inp_shape.append(-1) # [16, 256] -> [16, 256, -1]\n",
    "\n",
    "    # Autoregressive Loop\n",
    "    for t in range(initial_step, t_train): # range(10, 40)\n",
    "        # Reshape input tensor into [b, x1, ..., xd, t_init*v]\n",
    "        inp = x.reshape(inp_shape) # (16, 256, 10)\n",
    "        temp_shape = [0, -1] \n",
    "        temp_shape.extend([i for i in range(1,len(inp.shape)-1)]) # [0, -1] -> [0, -1, 1]\n",
    "        inp = inp.permute(temp_shape) # (16, 10, 256)\n",
    "        # Extract target of current time step\n",
    "        target = y[..., t:t+1, :] # (16, 256, 1, 1)\n",
    "        # run model to predict\n",
    "        temp_shape = [0]\n",
    "        temp_shape.extend([i for i in range(2,len(inp.shape))]) # [0] -> [0, 2]\n",
    "        temp_shape.append(1) # [0, 2] -> [0, 2, 1] \n",
    "        if t < t_train - unroll_step: # 21\n",
    "            with torch.no_grad():\n",
    "                im = model(inp).permute(temp_shape).unsqueeze(-2) # (16, 1, 256) -> (16, 256, 1) -> (16, 256, 1, 1)\n",
    "        else:\n",
    "            im = model(inp).permute(temp_shape).unsqueeze(-2) # (16, 10, 256) -> (16, 1, 256) -> (16, 256, 1, 1)\n",
    "            # compute loss\n",
    "            loss += loss_fn(im.reshape(batch_size, -1), target.reshape(batch_size, -1))\n",
    "        # Concatenate the prediction at current time step into the prediction tensor\n",
    "        pred = torch.cat((pred, im), -2) # (16, 256, 11, 1) \n",
    "        # construct the input of next time step \n",
    "        x = torch.cat((x[..., 1:, :], im), dim=-2) # (16, 256, 10, 1)\n",
    "        \n",
    "    train_l2_step += loss.item() # step loss\n",
    "    print(train_l2_step)\n",
    "    _batch = y.size(0) # 16\n",
    "    _y = y[..., :t_train, :] # (16, 256, 41, 1)\n",
    "    l2_full = loss_fn(pred.reshape(_batch, -1), _y.reshape(_batch, -1))\n",
    "    train_l2_full += l2_full.item() # total loss (我认为和step loss是一回事)\n",
    "    # update weight of model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward() # 只用unrolled time step之后的损失更新模型参数\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not pushforward\n",
    "x, y = next(iter(train_loader))\n",
    "loss = 0\n",
    "x = x.to(device) # (bs, x, t, v): (16, 256, 10, 1)\n",
    "y = y.to(device) # (bs, x, t, v): (16, 256, 41, 1)\n",
    "pred = y[..., :initial_step, :] # (16, 256, 10, 1)\n",
    "inp_shape = list(x.shape) # [16, 256, 10, 1]\n",
    "inp_shape = inp_shape[:-2] # [16, 256]\n",
    "inp_shape.append(-1) # [16, 256] -> [16, 256, -1]\n",
    "t_train = min(t_train, y.shape[-2])\n",
    "\n",
    "# autoregressive loop\n",
    "for t in range(initial_step, t_train):\n",
    "    inp = y[..., t-initial_step:t, :].reshape(inp_shape) # (16, 256, 10, 1) -> (16, 256, 10)\n",
    "    temp_shape = [0, -1]\n",
    "    temp_shape.extend([i for i in range(1, len(inp.shape)-1)]) # [0, -1] -> [0, -1, 1]\n",
    "    inp = inp.permute(temp_shape) # (16, 256, 10) -> (16, 10, 256)\n",
    "\n",
    "    target = y[..., t:t+1, :] # (16, 256, 1, 1)\n",
    "\n",
    "    temp_shape = [0]\n",
    "    temp_shape.extend([i for i in range(2,len(inp.shape))]) # [0] -> [0, 2]\n",
    "    temp_shape.append(1) # [0, 2, 1]\n",
    "    im = model(inp).permute(temp_shape).unsqueeze(-2) # (16, 10, 256) -> (16, 1, 256) -> (16, 256, 1, 1)\n",
    "\n",
    "    loss += loss_fn(im.reshape(batch_size, -1), target.reshape(batch_size, -1))\n",
    "\n",
    "    pred = torch.cat((pred, im), -2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdebench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
